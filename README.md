# Must Read Papers for ML Newbie (Updated Sep'23)

> üí° Î®∏Ïã†Îü¨Îãù-Îî•Îü¨Îãù ÏûÖÎ¨∏ÏûêÍ∞Ä Íº≠ ÏùΩÏñ¥Ïïº Ìï† ÎÖºÎ¨∏ Î¶¨Ïä§Ìä∏

## Ïª¥Ìì®ÌÑ∞ ÎπÑÏ†Ñ (Computer Vision):

- [AlexNet: Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet Classification with Deep Convolutional Neural Networks.](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
- [VGGNet: Simonyan, K., & Zisserman, A. (2014). Very Deep Convolutional Networks for Large-Scale Image Recognition.](https://arxiv.org/abs/1409.1556)
- [GoogLeNet (Inception): Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., ... & Rabinovich, A. (2015). Going Deeper with Convolutions.](https://arxiv.org/abs/1409.4842)
- [ResNet: He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition.](https://arxiv.org/abs/1512.03385)
- [YOLO (You Only Look Once): Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). You Only Look Once: Unified, Real-Time Object Detection.](https://arxiv.org/abs/1506.02640)
- [Mask R-CNN: He, K., Gkioxari, G., Doll√°r, P., & Girshick, R. (2017). Mask R-CNN.](https://arxiv.org/abs/1703.06870)
- [BERT: Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Bidirectional Encoder Representations from Transformers.](https://arxiv.org/abs/1810.04805)

## ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ (Natural Language Processing, NLP):

- [Word2Vec: Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed Representations of Words and Phrases and their Compositionality.](https://arxiv.org/abs/1310.4546)
- [LSTM (Long Short-Term Memory): Hochreiter, S., & Schmidhuber, J. (1997). Long Short-Term Memory.](https://www.bioinf.jku.at/publications/older/2604.pdf)
- [Attention is All You Need: Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Kaiser, ≈Å. (2017). Attention Is All You Need.](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjam7D8h5-BAxXqsFYBHQMSC0IQFnoECBAQAQ&url=https%3A%2F%2Farxiv.org%2Fabs%2F1706.03762&usg=AOvVaw2ceXGQohV5Kx51VSkfkG08&opi=89978449)
- [BERT: Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Bidirectional Encoder Representations from Transformers.](https://arxiv.org/abs/1810.04805)
- [GPT-3: Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., ... & Amodei, D. (2020). Language Models are Few-Shot Learners.](https://arxiv.org/abs/2005.14165)

## ÏùåÏÑ± Ï≤òÎ¶¨ (Speech Processing):

- [Deep Speech: Hinton, G., Deng, L., Yu, D., Dahl, G. E., Mohamed, A. R., Jaitly, N., ... & Kingsbury, B. (2012). Deep Neural Networks for Acoustic Modeling in Speech Recognition.](https://ieeexplore.ieee.org/document/6296526)
- [Wavenet: van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., ... & Kavukcuoglu, K. (2016). Wavenet: A Generative Model for Raw Audio.](https://arxiv.org/abs/1609.03499)
- [Listen, Attend and Spell (LAS): Chan, W., Jaitly, N., Le, Q., & Vinyals, O. (2016). Listen, Attend and Spell.](https://arxiv.org/abs/1508.01211)

## Í∞ïÌôî ÌïôÏäµ (Reinforcement Learning):

- [DQN (Deep Q-Network): Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... & Petersen, S. (2015). Human-level control through deep reinforcement learning. ](https://www.nature.com/articles/nature14236)
- [A3C (Asynchronous Advantage Actor-Critic): Mnih, V., Badia, A. P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., ... & Kavukcuoglu, K. (2016). Asynchronous methods for deep reinforcement learning.](https://arxiv.org/abs/1602.01783)
- [PPO (Proximal Policy Optimization): Schulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2017). Proximal Policy Optimization Algorithms.](https://arxiv.org/abs/1707.06347)
- [D3QN (Distributed Distributional Deterministic Policy Gradients): Barth-Maron, G., Hoffman, M. W., Budden, D., Dabney, W., Horgan, D., Muldal, A., ... & Lillicrap, T. (2018). Distributed Distributional Deterministic Policy Gradients.](https://arxiv.org/abs/1804.08617)

<!--
## Ïª¥Ìì®ÌÑ∞ ÎπÑÏ†Ñ (Computer Vision):
### Ïù¥ÎØ∏ÏßÄ Î∂ÑÎ•ò (Image Classification): Ïù¥ÎØ∏ÏßÄÍ∞Ä Ïñ¥Îñ§ Í∞ùÏ≤¥ÎÇò Ïπ¥ÌÖåÍ≥†Î¶¨Ïóê ÏÜçÌïòÎäîÏßÄ Î∂ÑÎ•òÌï©ÎãàÎã§.
### Í∞ùÏ≤¥ Í≤ÄÏ∂ú (Object Detection): Ïù¥ÎØ∏ÏßÄ ÎÇ¥ÏóêÏÑú Í∞ùÏ≤¥Ïùò ÏúÑÏπòÎ•º Ï∞æÍ≥† Í≤ΩÍ≥Ñ ÏÉÅÏûêÎ•º Í∑∏Î¶ΩÎãàÎã§.
### ÏñºÍµ¥ Ïù∏Ïãù (Face Recognition): ÏñºÍµ¥ÏùÑ Ïù∏ÏãùÌïòÍ≥† Í∞úÎ≥Ñ ÏñºÍµ¥ÏùÑ ÏãùÎ≥ÑÌï©ÎãàÎã§.
### Ïù¥ÎØ∏ÏßÄ Î∂ÑÌï† (Image Segmentation): Ïù¥ÎØ∏ÏßÄÎ•º ÌîΩÏÖÄ ÏàòÏ§ÄÏóêÏÑú Í∞ùÏ≤¥Î°ú Î∂ÑÌï†Ìï©ÎãàÎã§.
### Ïä§ÌÉÄÏùº Î≥ÄÌôò (Style Transfer): Ìïú Ïù¥ÎØ∏ÏßÄÏùò Ïä§ÌÉÄÏùºÏùÑ Îã§Î•∏ Ïù¥ÎØ∏ÏßÄÏóê Ï†ÅÏö©Ìï©ÎãàÎã§.
### ÏûêÏú® Ï£ºÌñâ ÏûêÎèôÏ∞® (Autonomous Vehicles): ÏûêÏú® Ï£ºÌñâ ÏûêÎèôÏ∞®ÏóêÏÑú ÏÑºÏÑú Îç∞Ïù¥ÌÑ∞Î•º Ï≤òÎ¶¨ÌïòÍ≥† ÌôòÍ≤ΩÏùÑ Ïù¥Ìï¥ÌïòÎäî Îç∞ ÌôúÏö©Îê©ÎãàÎã§.

## ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ (Natural Language Processing, NLP):
### ÌÖçÏä§Ìä∏ Î∂ÑÎ•ò (Text Classification): ÌÖçÏä§Ìä∏Î•º Ïπ¥ÌÖåÍ≥†Î¶¨Î°ú Î∂ÑÎ•òÌïòÍ±∞ÎÇò Í∞êÏ†ïÏùÑ Î∂ÑÏÑùÌï©ÎãàÎã§.
### Í∏∞Í≥Ñ Î≤àÏó≠ (Machine Translation): Ïñ∏Ïñ¥ Í∞Ñ Î≤àÏó≠ÏùÑ ÏàòÌñâÌï©ÎãàÎã§.
### Í∞úÏ≤¥Î™Ö Ïù∏Ïãù (Named Entity Recognition, NER): ÌÖçÏä§Ìä∏ÏóêÏÑú Î™ÖÏÇ¨ÎÇò Í∞úÏ≤¥Î•º ÏãùÎ≥ÑÌï©ÎãàÎã§.
### Î¨∏ÏÑú ÏöîÏïΩ (Text Summarization): Í∏¥ ÌÖçÏä§Ìä∏Î•º ÏöîÏïΩÌïòÏó¨ ÌïµÏã¨ ÎÇ¥Ïö©ÏùÑ Ï∂îÏ∂úÌï©ÎãàÎã§.
### Í∞êÏ†ï Î∂ÑÏÑù (Sentiment Analysis): ÌÖçÏä§Ìä∏Ïùò Í∞êÏ†ï ÌÜ§ÏùÑ Î∂ÑÏÑùÌï©ÎãàÎã§.
### ÏßàÏùò ÏùëÎãµ ÏãúÏä§ÌÖú (Question Answering Systems): ÏßàÎ¨∏Ïóê ÎåÄÌïú ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.

## ÏùåÏÑ± Ï≤òÎ¶¨ (Speech Processing):
### ÏùåÏÑ± Ïù∏Ïãù (Speech Recognition): ÏùåÏÑ±ÏùÑ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôòÌï©ÎãàÎã§.
### ÏùåÏÑ± Ìï©ÏÑ± (Speech Synthesis): ÌÖçÏä§Ìä∏Î•º ÏùåÏÑ±ÏúºÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§.
### ÌôîÏûê Ïù∏Ïãù (Speaker Recognition): ÌäπÏ†ï ÌôîÏûêÎ•º Ïù∏ÏãùÌï©ÎãàÎã§.
### ÏùåÏÑ± Í∞êÏ†ï Î∂ÑÏÑù (Speech Emotion Analysis): ÏùåÏÑ±ÏóêÏÑú Í∞êÏ†ïÏùÑ Î∂ÑÏÑùÌï©ÎãàÎã§.

## Í∞ïÌôî ÌïôÏäµ (Reinforcement Learning):
### ÏóêÏù¥Ï†ÑÌä∏Í∞Ä ÌôòÍ≤ΩÍ≥º ÏÉÅÌò∏ ÏûëÏö©ÌïòÎ©∞ Î≥¥ÏÉÅÏùÑ ÏµúÎåÄÌôîÌïòÎäî Î∞©Î≤ïÏùÑ ÌïôÏäµÌï©ÎãàÎã§.
### Í≤åÏûÑ, Î°úÎ¥á Ï†úÏñ¥, Í∏àÏúµ Í±∞Îûò Îì± Îã§ÏñëÌïú ÏùëÏö© Î∂ÑÏïºÏóêÏÑú ÏÇ¨Ïö©Îê©ÎãàÎã§.

## ÏÉùÏÑ±Ï†Å Î™®Îç∏ (Generative Models):
### ÏÉùÏÑ±Ï†Å Ï†ÅÎåÄ Ïã†Í≤ΩÎßù (Generative Adversarial Networks, GANs): Ïù¥ÎØ∏ÏßÄ, ÏùåÏÑ±, ÌÖçÏä§Ìä∏ Îì±Ïùò Îç∞Ïù¥ÌÑ∞Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
### Î≥ÄÏù¥Ìòï Ïò§ÌÜ†Ïù∏ÏΩîÎçî (Variational Autoencoders, VAEs): Îç∞Ïù¥ÌÑ∞Î•º ÏÉùÏÑ±ÌïòÍ≥† Î∂ÑÏÑùÌïòÎäî Îç∞ ÏÇ¨Ïö©Îê©ÎãàÎã§.

## Í∞ÅÏ¢Ö ÏùëÏö© Î∂ÑÏïº:
### ÏùòÎ£å Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑù (Medical Image Analysis)
### Í∏àÏúµ ÏòàÏ∏° (Financial Forecasting)
### ÌôîÌïô Î∞è Î∂ÑÏûê Î™®Îç∏ÎßÅ (Chemistry and Molecular Modeling)
### Í≤åÏûÑ Í∞úÎ∞ú (Game Development)
### Î°úÎ¥á Í≥µÌïô (Robotics)
### ÌôòÍ≤Ω Î™®ÎãàÌÑ∞ÎßÅ (Environmental Monitoring)
-->


<!--
## CNN (Convolutional Neural Network) 

### 

### Computer Vision

- [Image Super-Resolution Using Deep Convolutional Networks](https://arxiv.org/abs/1501.00092)
-->

<!--
CNN (Convolutional Neural Network) 
LSTM (Long Short-Term Memory)
RNN (Recurrent Neural Network)
GAN (Generation Attemarical Network)
RBFN (Radial Basis Function Network)
MLP (Multi-Layer Perceptron)
SOM (Self Organization Map)
DBN (Deep Belief Networks)
RBM (Restricted Boltzmann Machine)
Autoencoder

ref: https://t.ly/othN4
-->
